{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from torch_cluster import random_walk\n",
    "from torch.utils.data import dataset,dataloader\n",
    "\n",
    "seed=1\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "common_set=torch.load('./data/train_data/common_set.pkl')\n",
    "train_set=torch.load('./data/train_data/train_set.pkl')\n",
    "test_set=torch.load('./data/train_data/test_set.pkl')\n",
    "\n",
    "kfolds=5\n",
    "batch=2048       \n",
    "adj_threshold=0.9\n",
    "nce_temp=1e+2   \n",
    "calpha=1.0\n",
    "input_dim=common_set['md'].shape[0]+common_set['md'].shape[1]+common_set['ml'].shape[1]\n",
    "rw_param={'rw_len':5,'rw_times':20,'rw_p':1,'rw_q':1}    \n",
    "C_model_param={'n_heads':2,     \n",
    "               'hidden_size':512,    \n",
    "               'lr':9e-5,            \n",
    "               'weight_decay':5e-4,   \n",
    "               'epochs':100}          \n",
    "P_model_param={'hidden_channle':8,   \n",
    "               'num_group':2,      \n",
    "               'gate_treshold':0.5,   \n",
    "               'dropout_rate':0.2,  \n",
    "               'lr':7e-5,           \n",
    "               'weight_decay':5e-4,   \n",
    "               'epochs':100}          \n",
    "\n",
    "device=torch.device('cuda')\n",
    "\n",
    "class MyDataset(dataset.Dataset):\n",
    "    def __init__(self, edges, labels, fea, prw, nrw, nm):\n",
    "        self.nm=nm\n",
    "        self.Data = edges\n",
    "        self.Label = labels\n",
    "        self.fea=fea\n",
    "        self.prw=prw\n",
    "        self.nrw=nrw\n",
    "    def __len__(self):\n",
    "        return len(self.Label)\n",
    "    def __getitem__(self, index):\n",
    "        xy = self.Data[index]\n",
    "        label = self.Label[index]\n",
    "        p_rw_m=self.fea[self.prw[xy[0]]]\n",
    "        p_rw_d=self.fea[self.prw[xy[1]+self.nm]]\n",
    "        n_rw_m=self.fea[self.nrw[xy[0]]]\n",
    "        n_rw_d=self.fea[self.nrw[xy[1]+self.nm]]\n",
    "        return xy, label, p_rw_m, p_rw_d, n_rw_m, n_rw_d\n",
    "\n",
    "    def __init__(self, kfolds, rw_param, adj_threshold, common_set, train_set, test_set):\n",
    "        self.nm=common_set['md'].shape[0]\n",
    "        self.rw_param=rw_param\n",
    "        self.kfolds=kfolds\n",
    "        self.adj_threshold=adj_threshold\n",
    "        self.feas,self.prws,self.nrws=[],[],[]\n",
    "    def negative_sampling(self,fea,prw):\n",
    "        for j in range(self.rw_param['rw_len']):\n",
    "            fea[prw[:,0],prw[:,j+1]]=0\n",
    "        return self.RandomWalk(fea)\n",
    "    def RandomWalk(self,fea):\n",
    "        adj=torch.argwhere(fea>self.adj_threshold)\n",
    "        rw_nodes=random_walk(adj[:,0],adj[:,1],torch.arange(fea.shape[0]).repeat_interleave(self.rw_param['rw_times']),\n",
    "                                walk_length=self.rw_param['rw_len'],p=self.rw_param['rw_p'],q=self.rw_param['rw_q'])\n",
    "        rws=[]\n",
    "        for j in range(fea.shape[0]):\n",
    "            rws.append([j])\n",
    "            for m in range(self.rw_param['rw_len']):\n",
    "                uv,co=torch.unique(rw_nodes[j*self.rw_param['rw_times']:(j+1)*self.rw_param['rw_times'],m],return_counts=True)\n",
    "                rws[j].append(uv[co.argmax()].item())\n",
    "        return torch.tensor(rws).long()\n",
    "    def tr_va_te_data_set(self, edge, label, batch, i):\n",
    "        return dataloader.DataLoader(MyDataset(edge, label, self.feas[i], self.prws[i], self.nrws[i], self.nm), batch_size=batch, shuffle=True, num_workers=0)\n",
    "class DataProcess():\n",
    "    def __init__(self, kfolds, rw_param, adj_threshold, common_set, train_set, test_set):\n",
    "        self.nm=common_set['md'].shape[0]\n",
    "        self.rw_param=rw_param\n",
    "        self.kfolds=kfolds\n",
    "        self.adj_threshold=adj_threshold\n",
    "        self.feas,self.prws,self.nrws=[],[],[]\n",
    "        fea=torch.cat([torch.cat([test_set['mm_mdF'],test_set['md']],dim=1),\n",
    "                        torch.cat([test_set['md'].t(),common_set['dd_sem']],dim=1)],dim=0)\n",
    "        self.prws.append(self.RandomWalk(fea))\n",
    "        self.nrws.append(self.negative_sampling(fea,self.prws[-1]))\n",
    "        fea=torch.cat([fea,torch.cat([common_set['ml'],common_set['dl']],dim=0)],dim=1)\n",
    "        self.feas.append(fea)\n",
    "    def negative_sampling(self,fea,prw):\n",
    "        for j in range(self.rw_param['rw_len']):\n",
    "            fea[prw[:,0],prw[:,j+1]]=0\n",
    "        return self.RandomWalk(fea)\n",
    "    def RandomWalk(self,fea):\n",
    "        adj=torch.argwhere(fea>self.adj_threshold)\n",
    "        rw_nodes=random_walk(adj[:,0],adj[:,1],torch.arange(fea.shape[0]).repeat_interleave(self.rw_param['rw_times']),\n",
    "                                walk_length=self.rw_param['rw_len'],p=self.rw_param['rw_p'],q=self.rw_param['rw_q'])\n",
    "        rws=[]\n",
    "        for j in range(fea.shape[0]):\n",
    "            rws.append([j])\n",
    "            for m in range(self.rw_param['rw_len']):\n",
    "                uv,co=torch.unique(rw_nodes[j*self.rw_param['rw_times']:(j+1)*self.rw_param['rw_times'],m],return_counts=True)\n",
    "                rws[j].append(uv[co.argmax()].item())\n",
    "        return torch.tensor(rws).long()\n",
    "    def tr_va_te_data_set(self, edge, label, batch, i):\n",
    "        return dataloader.DataLoader(MyDataset(edge, label, self.feas[i], self.prws[i], self.nrws[i], self.nm), batch_size=batch, shuffle=True, num_workers=0)\n",
    "def caculate_metrics(p_m,l_m,act_type='softmax'):\n",
    "    if act_type=='softmax':\n",
    "        fl_p=torch.softmax(p_m,dim=1)[:,1].numpy()\n",
    "        ol_p=torch.argmax(p_m,dim=1).numpy()\n",
    "    elif act_type=='sigmoid':\n",
    "        fl_p=p_m.numpy()\n",
    "        ol_p=(p_m>0.5).long().numpy()\n",
    "    l_m=l_m.numpy()\n",
    "    p,r,_= metrics.precision_recall_curve(l_m,fl_p)\n",
    "    metric_result=[metrics.roc_auc_score(l_m,fl_p),metrics.auc(r, p),metrics.accuracy_score(l_m,ol_p),\n",
    "                                    metrics.f1_score(l_m,ol_p),metrics.recall_score(l_m,ol_p)]\n",
    "    print(\"auc:\"+str(metric_result[0])+\";aupr:\"+str(metric_result[1])+\";accuracy:\"+str(metric_result[2])+\";f1_score:\"+str(metric_result[3])+\";recall:\"+str(metric_result[4]))\n",
    "    return metric_result\n",
    "class EarlyStopping:\n",
    "    def __init__(self,savepath,patience=3,delta=0):  \n",
    "        self.savepath=savepath\n",
    "        self.patience=patience\n",
    "        self.bestscore=None\n",
    "        self.delta=delta\n",
    "        self.counter=0\n",
    "        self.earlystop=False\n",
    "    def __call__(self,score,model):\n",
    "        fscore=-score\n",
    "        if self.bestscore is None:\n",
    "            self.bestscore=fscore\n",
    "            torch.save(model.state_dict(),self.savepath)\n",
    "        elif fscore<self.bestscore+self.delta:\n",
    "            self.counter+=1\n",
    "            if self.counter>=self.patience:\n",
    "                self.earlystop=True\n",
    "        else:\n",
    "            self.bestscore=fscore\n",
    "            torch.save(model.state_dict(),self.savepath)\n",
    "            self.counter=0\n",
    "def info_NCE_loss(p_output,n_output,nce_temp):\n",
    "        zd=torch.exp(p_output[:,0:1,:]@n_output.transpose(1,2)/nce_temp)\n",
    "        sm=-torch.log(zd[:,0,0]+1e-8)\n",
    "        xm=torch.log(zd[:,0,:].sum(-1)+1e-8)\n",
    "        return (sm+xm).mean()\n",
    "def contrastive_loss(p_n_output,p_r_output,n_n_output,n_r_output,nce_temp,calpha):\n",
    "        p_n_m,p_n_d=torch.split(p_n_output,p_n_output.shape[1]//2,dim=1)\n",
    "        n_n_m,n_n_d=torch.split(n_n_output,n_n_output.shape[1]//2,dim=1)\n",
    "        node_loss=info_NCE_loss(p_n_m,n_n_m,nce_temp)+info_NCE_loss(p_n_d,n_n_d,nce_temp)\n",
    "        relation_loss=(p_r_output*n_r_output).sum(-1)/(torch.sqrt((p_r_output**2).sum(-1))*torch.sqrt((n_r_output**2).sum(-1)))\n",
    "        relation_loss=(relation_loss+1)/2\n",
    "        return node_loss+calpha*relation_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32412\\3534806107.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mCNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwalk_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCNet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmn1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdn1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class CNet(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,heads,walk_len):\n",
    "        super(CNet,self).__init__()\n",
    "        self.ml1,self.dl1=nn.Linear(input_dim,hidden_dim),nn.Linear(input_dim,hidden_dim)\n",
    "        self.mn1,self.dn1=nn.LayerNorm(hidden_dim),nn.LayerNorm(hidden_dim)\n",
    "        self.LMHA=nn.MultiheadAttention(hidden_dim,heads,batch_first=True)\n",
    "        self.Ln=nn.LayerNorm(hidden_dim)\n",
    "        self.ml2,self.dl2=nn.Linear(walk_len,1),nn.Linear(walk_len,1)\n",
    "        self.mn2,self.dn2=nn.LayerNorm(hidden_dim),nn.LayerNorm(hidden_dim)\n",
    "        self.GMHA=nn.MultiheadAttention(hidden_dim,heads,batch_first=True)\n",
    "        self.Gn=nn.LayerNorm(hidden_dim)\n",
    "        self.reset_parameters()\n",
    "    def forward(self,xm,xd):\n",
    "        xm,xd=self.mn1(self.ml1(xm)),self.dn1(self.dl1(xd))\n",
    "        xmd=torch.cat([xm,xd],dim=1)\n",
    "        nx=self.Ln(self.LMHA(xmd,xmd,xmd)[0])\n",
    "        xm=self.mn2(self.ml2(xm.transpose(1,2)).transpose(1,2))\n",
    "        xd=self.dn2(self.dl2(xd.transpose(1,2)).transpose(1,2))\n",
    "        xmd=torch.cat([xm,xd],dim=1)\n",
    "        rx=self.Gn(self.GMHA(xmd,xmd,xmd)[0])\n",
    "        return nx,rx\n",
    "\n",
    "class PNet(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,hidden_channle,num_group,gate_treshold=0.5,dropout_rate=0):\n",
    "        super(PNet,self).__init__()\n",
    "        self.proj1=nn.Linear(input_dim,hidden_dim)\n",
    "        self.proj2=nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.norm=nn.LayerNorm(hidden_dim)\n",
    "        self.conv1=nn.Conv2d(1,hidden_channle,kernel_size=(1,1),stride=1,padding=0)\n",
    "        self.gn=nn.GroupNorm(num_groups=num_group,num_channels=hidden_channle)\n",
    "        self.gate_treshold=gate_treshold\n",
    "        self.gc=nn.Conv2d(hidden_channle,num_group,kernel_size=(2,7),stride=(2,7),padding=0,groups=num_group)\n",
    "        self.pool=nn.AdaptiveAvgPool2d((16,512))\n",
    "        self.l1=nn.Linear(num_group*1024,512)\n",
    "        self.dropout=nn.Dropout(dropout_rate)\n",
    "        self.l2=nn.Linear(512,2)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.leakyrelu=nn.LeakyReLU()\n",
    "        self.reset_parameters()\n",
    "    def forward(self,x1,x2):\n",
    "        x=torch.cat([self.proj1(x1),self.proj2(x2)],dim=0)\n",
    "        x=self.norm(x)\n",
    "        x=self.leakyrelu(self.conv1(x[:,None,:,:]))\n",
    "        gn_x=self.gn(x)\n",
    "        w_gamma=self.gn.weight/sum(self.gn.weight)\n",
    "        reweight=self.sigmoid(gn_x*w_gamma[None,:,None,None])\n",
    "        x1=torch.where(reweight>self.gate_treshold,torch.ones_like(reweight),reweight)*x\n",
    "        x2=torch.where(reweight<self.gate_treshold,torch.zeros_like(reweight),reweight)*x\n",
    "        x11,x12=torch.split(x1,x1.size(1)//2,dim=1)\n",
    "        x21,x22=torch.split(x2,x2.size(1)//2,dim=1)\n",
    "        x=torch.cat([x11+x22,x12+x21],dim=1)\n",
    "        x=self.pool(self.leakyrelu(self.gc(x)))\n",
    "        return self.l2(self.dropout(self.l1(x.reshape(x.shape[0],-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_43376\\1577321058.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mCmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss_total\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_rw_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_rw_d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_rw_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_rw_d\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mp_n_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_r_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_rw_m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_rw_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mn_n_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_r_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_rw_m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_rw_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\app2\\miniconda\\install\\envs\\venv_py37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\app2\\miniconda\\install\\envs\\venv_py37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\app2\\miniconda\\install\\envs\\venv_py37\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\app2\\miniconda\\install\\envs\\venv_py37\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_43376\\2563445132.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mxy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mp_rw_m\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfea\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0mp_rw_d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfea\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mn_rw_m\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfea\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnrw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_metric = []\n",
    "DP=DataProcess(kfolds, rw_param, adj_threshold, common_set, train_set, test_set)\n",
    "testLoader = DP.tr_va_te_data_set(test_set['edge'], test_set['label'], batch, -1)\n",
    "for i in range(kfolds):\n",
    "    ES=EarlyStopping(\"./models/ZC_Cmodel_fold_%d.pkl\"%i,patience=3)\n",
    "    Cmodel=CNet(input_dim,C_model_param['hidden_size'],C_model_param['n_heads'],rw_param['rw_len']+1).to(device)\n",
    "    optimizer = torch.optim.Adam(Cmodel.parameters(), lr=C_model_param['lr'], weight_decay=C_model_param['weight_decay'])\n",
    "    trainLoader = DP.tr_va_te_data_set(train_set['edge_train_%d'%i], train_set['label_train_%d'%i], batch, i)\n",
    "    validLoader = DP.tr_va_te_data_set(train_set['edge_valid_%d'%i], train_set['label_valid_%d'%i], batch, i)\n",
    "    for e in range(C_model_param['epochs']):\n",
    "        Cmodel.train()\n",
    "        loss_total=0\n",
    "        for _, _, p_rw_m, p_rw_d, n_rw_m, n_rw_d in trainLoader:\n",
    "            p_n_output,p_r_output=Cmodel(p_rw_m.float().to(device),p_rw_d.float().to(device))\n",
    "            n_n_output,n_r_output=Cmodel(n_rw_m.float().to(device),n_rw_d.float().to(device))\n",
    "            loss=contrastive_loss(p_n_output,p_r_output,n_n_output,n_r_output,nce_temp,calpha)\n",
    "            loss_total+=loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('fold:'+str(i+1)+';epoch'+str(e+1)+':'+str(loss_total))\n",
    "        ES(loss_total,Cmodel)\n",
    "        if ES.earlystop :\n",
    "            print('contrastive learning stop')\n",
    "            break\n",
    "    ES=EarlyStopping(\"./models/ZC_Pmodel_fold_%d.pkl\"%i,patience=3)\n",
    "    Pmodel=PNet(input_dim,C_model_param['hidden_size'],P_model_param['hidden_channle'],P_model_param['num_group'],\n",
    "                P_model_param['gate_treshold'],P_model_param['dropout_rate']).to(device)\n",
    "    Cmodel.load_state_dict(torch.load(\"./models/ZC_Cmodel_fold_%d.pkl\"%i))\n",
    "    optimizer = torch.optim.Adam(Pmodel.parameters(), lr=P_model_param['lr'], weight_decay=P_model_param['weight_decay'])\n",
    "    cost=nn.CrossEntropyLoss()\n",
    "    for e in range(P_model_param['epochs']):\n",
    "        Pmodel.train()\n",
    "        for data, label, p_rw_m, p_rw_d, _, _ in trainLoader:\n",
    "            n_x,r_x=Cmodel(p_rw_m.float().to(device),p_rw_d.float().to(device))\n",
    "            output=Pmodel(torch.cat([p_rw_m[:,0:1,:].float().to(device),p_rw_d[:,0:1,:].float().to(device)],dim=1),\n",
    "                          torch.cat([n_x.detach(),r_x.detach()],dim=1))\n",
    "            loss=cost(output,label.long().to(device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        Pmodel.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_total=0\n",
    "            for data, label, p_rw_m, p_rw_d, _, _ in validLoader:\n",
    "                n_x,r_x=Cmodel(p_rw_m.float().to(device),p_rw_d.float().to(device))\n",
    "                output=Pmodel(torch.cat([p_rw_m[:,0:1,:].float().to(device),p_rw_d[:,0:1,:].float().to(device)],dim=1),\n",
    "                              torch.cat([n_x.detach(),r_x.detach()],dim=1))\n",
    "                loss=cost(output,label.long().to(device))\n",
    "            loss_total+=loss.item()\n",
    "        print('fold:'+str(i+1)+';epoch'+str(e+1)+':'+str(loss_total))\n",
    "        ES(loss_total,Pmodel)\n",
    "        if ES.earlystop :\n",
    "            print('stop')\n",
    "            break\n",
    "    l_m,p_m=[],[]\n",
    "    Pmodel.load_state_dict(torch.load(\"./models/ZC_Pmodel_fold_%d.pkl\"%i))\n",
    "    Pmodel.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label, p_rw_m, p_rw_d, _, _ in testLoader:\n",
    "            n_x,r_x=Cmodel(p_rw_m.float().to(device),p_rw_d.float().to(device))\n",
    "            output=Pmodel(torch.cat([p_rw_m[:,0:1,:].float().to(device),p_rw_d[:,0:1,:].float().to(device)],dim=1),\n",
    "                          torch.cat([n_x.detach(),r_x.detach()],dim=1))\n",
    "            l_m.append(label.float())\n",
    "            p_m.append(output.cpu().detach())\n",
    "    test_metric.append(caculate_metrics(torch.cat(p_m,dim=0),torch.cat(l_m,dim=0),'softmax'))\n",
    "    if only_one:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
